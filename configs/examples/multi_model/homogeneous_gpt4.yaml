# Multi-Model Configuration Example: Homogeneous GPT-4
# This example shows how to configure an experiment where all agents use GPT-4
# WARNING: This is an experimental feature. Enable at your own risk.

# Basic experiment parameters
NUM_AGENTS: 10
NUM_ROUNDS: 5
NUM_ITERATIONS_PER_ROUND: 10
MAX_MESSAGE_HISTORY: 5
TEMPERATURE: 0.7

# Enable multi-model support (experimental feature)
ENABLE_MULTI_MODEL: true

# Model configurations
# Define available models and their parameters
model_configs:
  openai/gpt-4:
    model_type: openai/gpt-4
    api_key_env: OPENROUTER_API_KEY  # Uses default key
    max_tokens: 1500
    temperature: 0.7
    rate_limit: 60  # requests per minute
    retry_delay: 1.0
    custom_params:
      top_p: 0.95

# Scenario definitions
# Each scenario specifies how many agents use each model
scenarios:
  - name: All GPT-4
    model_distribution:
      openai/gpt-4: 10  # All 10 agents use GPT-4

# Default models for backward compatibility
MAIN_MODEL: google/gemini-2.5-flash  # Used when multi-model disabled
SUB_MODEL: openai/gpt-4.1-mini      # Used for subagent decisions

# Logging configuration
LOG_LEVEL: INFO
SAVE_AGENT_RESPONSES: true
SAVE_GAME_HISTORY: true

# API configuration
API_BASE_URL: https://openrouter.ai/api/v1/chat/completions
API_TIMEOUT: 30
API_MAX_RETRIES: 3

# Output configuration
OUTPUT_DIR: results
EXPERIMENT_NAME: homogeneous_gpt4_experiment