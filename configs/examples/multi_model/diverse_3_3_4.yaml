# Multi-Model Configuration Example: Diverse Model Mix
# This example shows how to configure an experiment with GPT-4, Claude, and Gemini
# WARNING: This is an experimental feature. Enable at your own risk.

# Basic experiment parameters
NUM_AGENTS: 10
NUM_ROUNDS: 5
NUM_ITERATIONS_PER_ROUND: 10
MAX_MESSAGE_HISTORY: 5
TEMPERATURE: 0.7

# Enable multi-model support (experimental feature)
ENABLE_MULTI_MODEL: true

# Model configurations
# Define available models and their parameters
model_configs:
  openai/gpt-4:
    model_type: openai/gpt-4
    api_key_env: OPENROUTER_API_KEY
    max_tokens: 1500
    temperature: 0.7
    rate_limit: 60
    retry_delay: 1.0
    custom_params:
      top_p: 0.95
  
  anthropic/claude-3-sonnet-20240229:
    model_type: anthropic/claude-3-sonnet-20240229
    api_key_env: OPENROUTER_API_KEY
    max_tokens: 1500
    temperature: 0.7
    rate_limit: 50
    retry_delay: 1.2
    custom_params:
      top_p: 0.9
  
  google/gemini-pro:
    model_type: google/gemini-pro
    api_key_env: OPENROUTER_API_KEY
    max_tokens: 1500
    temperature: 0.7
    rate_limit: 60
    retry_delay: 1.0
    custom_params:
      top_k: 40

# Scenario definitions
# Multiple scenarios can be defined - specify which one to use at runtime
scenarios:
  - name: Diverse Three Models
    model_distribution:
      openai/gpt-4: 3                          # 3 agents use GPT-4
      anthropic/claude-3-sonnet-20240229: 3    # 3 agents use Claude
      google/gemini-pro: 4                     # 4 agents use Gemini
  
  - name: GPT-4 Majority
    model_distribution:
      openai/gpt-4: 6                          # 6 agents use GPT-4
      anthropic/claude-3-sonnet-20240229: 2    # 2 agents use Claude
      google/gemini-pro: 2                     # 2 agents use Gemini
  
  - name: Equal Distribution
    model_distribution:
      openai/gpt-4: 4                          # 4 agents use GPT-4
      anthropic/claude-3-sonnet-20240229: 3    # 3 agents use Claude
      google/gemini-pro: 3                     # 3 agents use Gemini

# Default models for backward compatibility
MAIN_MODEL: google/gemini-2.5-flash  # Used when multi-model disabled
SUB_MODEL: openai/gpt-4.1-mini      # Used for subagent decisions

# Logging configuration
LOG_LEVEL: INFO
SAVE_AGENT_RESPONSES: true
SAVE_GAME_HISTORY: true

# API configuration
API_BASE_URL: https://openrouter.ai/api/v1/chat/completions
API_TIMEOUT: 30
API_MAX_RETRIES: 3

# Output configuration
OUTPUT_DIR: results
EXPERIMENT_NAME: diverse_models_experiment

# Usage:
# python run_experiment.py --config configs/examples/multi_model/diverse_3_3_4.yaml --scenario "Diverse Three Models"
#
# Notes:
# - Each model may have different response characteristics
# - Rate limits are per-model to prevent throttling
# - Fallback to default model ensures experiment continuity