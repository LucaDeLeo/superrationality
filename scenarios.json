{
  "scenarios": [
    {
      "name": "baseline_gemini",
      "description": "All agents use Google Gemini 2.5 Flash (baseline)",
      "model_distribution": {
        "google/gemini-2.5-flash": 10
      }
    },
    {
      "name": "homogeneous_gpt4o",
      "description": "All agents use OpenAI GPT-4o",
      "model_distribution": {
        "openai/gpt-4o": 10
      }
    },
    {
      "name": "homogeneous_claude_sonnet",
      "description": "All agents use Anthropic Claude 3 Sonnet",
      "model_distribution": {
        "anthropic/claude-3-sonnet": 10
      }
    },
    {
      "name": "homogeneous_llama3",
      "description": "All agents use Meta Llama 3 70B",
      "model_distribution": {
        "meta-llama/llama-3-70b-instruct": 10
      }
    },
    {
      "name": "mixed_gemini_gpt",
      "description": "50% Gemini, 50% GPT-4o",
      "model_distribution": {
        "google/gemini-2.5-flash": 5,
        "openai/gpt-4o": 5
      }
    },
    {
      "name": "mixed_gemini_claude",
      "description": "50% Gemini, 50% Claude Sonnet",
      "model_distribution": {
        "google/gemini-2.5-flash": 5,
        "anthropic/claude-3-sonnet": 5
      }
    },
    {
      "name": "mixed_gpt_claude",
      "description": "50% GPT-4o, 50% Claude Sonnet",
      "model_distribution": {
        "openai/gpt-4o": 5,
        "anthropic/claude-3-sonnet": 5
      }
    },
    {
      "name": "diverse_top_models",
      "description": "Mix of top 4 models",
      "model_distribution": {
        "google/gemini-2.5-flash": 3,
        "openai/gpt-4o": 3,
        "anthropic/claude-3-sonnet": 2,
        "meta-llama/llama-3-70b-instruct": 2
      }
    },
    {
      "name": "diverse_with_mistral",
      "description": "Including Mistral in the mix",
      "model_distribution": {
        "google/gemini-2.5-flash": 2,
        "openai/gpt-4o": 2,
        "anthropic/claude-3-sonnet": 2,
        "meta-llama/llama-3-70b-instruct": 2,
        "mistralai/mixtral-8x7b-instruct": 2
      }
    },
    {
      "name": "test_small",
      "description": "Small test with 2 agents",
      "model_distribution": {
        "google/gemini-2.5-flash": 1,
        "openai/gpt-4o": 1
      },
      "num_agents_override": 2
    },
    {
      "name": "homogeneous_claude_opus",
      "description": "All agents use Anthropic Claude 3 Opus (most capable)",
      "model_distribution": {
        "anthropic/claude-3-opus": 10
      }
    },
    {
      "name": "homogeneous_gpt4_turbo",
      "description": "All agents use OpenAI GPT-4 Turbo",
      "model_distribution": {
        "openai/gpt-4-turbo": 10
      }
    },
    {
      "name": "homogeneous_gemini_pro",
      "description": "All agents use Google Gemini Pro",
      "model_distribution": {
        "google/gemini-pro": 10
      }
    },
    {
      "name": "homogeneous_mistral_large",
      "description": "All agents use Mistral Large",
      "model_distribution": {
        "mistralai/mistral-large": 10
      }
    },
    {
      "name": "homogeneous_llama3_8b",
      "description": "All agents use Meta Llama 3 8B (smaller model)",
      "model_distribution": {
        "meta-llama/llama-3-8b-instruct": 10
      }
    },
    {
      "name": "homogeneous_qwen2_72b",
      "description": "All agents use Qwen2 72B",
      "model_distribution": {
        "qwen/qwen-2-72b-instruct": 10
      }
    },
    {
      "name": "homogeneous_command_r_plus",
      "description": "All agents use Cohere Command R+",
      "model_distribution": {
        "cohere/command-r-plus": 10
      }
    },
    {
      "name": "homogeneous_deepseek",
      "description": "All agents use DeepSeek Chat V2",
      "model_distribution": {
        "deepseek/deepseek-chat": 10
      }
    },
    {
      "name": "homogeneous_phi3_medium",
      "description": "All agents use Microsoft Phi-3 Medium",
      "model_distribution": {
        "microsoft/phi-3-medium-128k-instruct": 10
      }
    },
    {
      "name": "homogeneous_yi_large",
      "description": "All agents use Yi-Large",
      "model_distribution": {
        "01-ai/yi-large": 10
      }
    },
    {
      "name": "mixed_opus_vs_gpt4turbo",
      "description": "50% Claude Opus vs 50% GPT-4 Turbo (battle of the best)",
      "model_distribution": {
        "anthropic/claude-3-opus": 5,
        "openai/gpt-4-turbo": 5
      }
    },
    {
      "name": "mixed_large_vs_small",
      "description": "Large models vs small models",
      "model_distribution": {
        "anthropic/claude-3-opus": 3,
        "openai/gpt-4-turbo": 3,
        "meta-llama/llama-3-8b-instruct": 2,
        "microsoft/phi-3-medium-128k-instruct": 2
      }
    },
    {
      "name": "diverse_all_providers",
      "description": "One model from each major provider",
      "model_distribution": {
        "openai/gpt-4o": 2,
        "anthropic/claude-3-sonnet": 2,
        "google/gemini-2.5-flash": 1,
        "meta-llama/llama-3-70b-instruct": 1,
        "mistralai/mistral-large": 1,
        "cohere/command-r-plus": 1,
        "deepseek/deepseek-chat": 1,
        "01-ai/yi-large": 1
      }
    },
    {
      "name": "budget_models_only",
      "description": "Only smaller/cheaper models",
      "model_distribution": {
        "meta-llama/llama-3-8b-instruct": 3,
        "microsoft/phi-3-medium-128k-instruct": 3,
        "mistralai/mixtral-8x7b-instruct": 2,
        "google/gemini-2.5-flash": 2
      }
    },
    {
      "name": "premium_models_only",
      "description": "Only top-tier expensive models",
      "model_distribution": {
        "anthropic/claude-3-opus": 3,
        "openai/gpt-4-turbo": 3,
        "google/gemini-pro": 2,
        "mistralai/mistral-large": 2
      }
    },
    {
      "name": "chinese_models_mix",
      "description": "Chinese-developed models",
      "model_distribution": {
        "qwen/qwen-2-72b-instruct": 4,
        "deepseek/deepseek-chat": 3,
        "01-ai/yi-large": 3
      }
    },
    {
      "name": "open_source_only",
      "description": "Only open-source models",
      "model_distribution": {
        "meta-llama/llama-3-70b-instruct": 3,
        "meta-llama/llama-3-8b-instruct": 2,
        "mistralai/mixtral-8x7b-instruct": 3,
        "qwen/qwen-2-72b-instruct": 2
      }
    },
    {
      "name": "chaos_maximum_diversity",
      "description": "Maximum diversity - 10 different models",
      "model_distribution": {
        "openai/gpt-4o": 1,
        "anthropic/claude-3-opus": 1,
        "google/gemini-pro": 1,
        "meta-llama/llama-3-70b-instruct": 1,
        "mistralai/mistral-large": 1,
        "cohere/command-r-plus": 1,
        "deepseek/deepseek-chat": 1,
        "qwen/qwen-2-72b-instruct": 1,
        "microsoft/phi-3-medium-128k-instruct": 1,
        "01-ai/yi-large": 1
      }
    }
  ]
}