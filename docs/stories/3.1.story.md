# Story 3.1: Round-Robin Tournament

## Status
Done

## Story
**As a** system,
**I need to** execute 45 games per round (all agent pairs),
**so that** every agent plays every other agent exactly once

## Acceptance Criteria
1. Each unique pair plays exactly once per round
2. Games executed in consistent order
3. No duplicate matchups

## Tasks / Subtasks
- [x] Task 1: Create GameExecutionFlow class structure (AC: 1, 2, 3)
  - [x] Subtask 1.1: Create GameExecutionFlow in src/flows/game_execution.py inheriting from AsyncFlow
  - [x] Subtask 1.2: Implement method to generate all unique agent pairs (i,j where i<j)
  - [x] Subtask 1.3: Store pairs in consistent order for deterministic execution
  - [x] Subtask 1.4: Add validation to ensure exactly 45 pairs for 10 agents
- [x] Task 2: Implement game matching logic (AC: 1, 3)
  - [x] Subtask 2.1: Create generate_round_matchups() method that returns List[Tuple[int, int]]
  - [x] Subtask 2.2: Ensure no agent plays themselves (i != j)
  - [x] Subtask 2.3: Ensure no duplicate pairs (only one of (i,j) or (j,i))
  - [x] Subtask 2.4: Add logging to track matchup generation
- [x] Task 3: Implement sequential game execution (AC: 2)
  - [x] Subtask 3.1: Create play_game() method that takes two Agent objects
  - [x] Subtask 3.2: Implement sequential execution loop through all matchups
  - [x] Subtask 3.3: Track game number within round (1-45)
  - [x] Subtask 3.4: Create GameResult objects with proper game_id format (r{round}_g{game_num})
- [x] Task 4: Integrate with existing round flow (AC: 1, 2, 3)
  - [x] Subtask 4.1: Import GameExecutionFlow in src/flows/experiment.py
  - [x] Subtask 4.2: Call GameExecutionFlow after strategy collection
  - [x] Subtask 4.3: Pass agents list and round number to GameExecutionFlow
  - [x] Subtask 4.4: Store returned games list in context
- [x] Task 5: Create unit tests for tournament logic (AC: 1, 2, 3)
  - [x] Subtask 5.1: Test generate_round_matchups() produces exactly 45 pairs
  - [x] Subtask 5.2: Test all pairs are unique (no duplicates)
  - [x] Subtask 5.3: Test each agent appears exactly 9 times
  - [x] Subtask 5.4: Test consistent ordering across multiple calls
  - [x] Subtask 5.5: Test game_id generation follows correct format

## Dev Notes

### Previous Story Insights
From Story 2.3 implementation:
- ExperimentFlow exists in src/flows/experiment.py and orchestrates the overall experiment
- DataManager is used for saving data with atomic writes
- AsyncFlow pattern is established for orchestrating operations
- Context dictionary pattern is used for passing data between nodes/flows

### Data Models
**Agent** [Source: architecture/data-models.md#agent]
```python
@dataclass
class Agent:
    id: int          # Unique identifier (0-9)
    power: float     # Current power level (50-150)
    strategy: str    # Current round strategy text
    total_score: float  # Cumulative payoff across all games
```

**GameResult** [Source: architecture/data-models.md#gameresult]
```python
@dataclass
class GameResult:
    game_id: str              # Unique identifier (r{round}_g{game_num} format)
    round: int                # Round number (1-10)
    player1_id: int           # First agent ID
    player2_id: int           # Second agent ID
    player1_action: str       # COOPERATE or DEFECT
    player2_action: str       # COOPERATE or DEFECT
    player1_payoff: float     # Calculated payoff for player1
    player2_payoff: float     # Calculated payoff for player2
    player1_power_before: float  # Power level before game
    player2_power_before: float  # Power level before game
    timestamp: str            # ISO timestamp of game execution
```

### Technical Specifications
**Round-Robin Tournament Requirements** [Source: Epic 3 PRD]
- Must generate exactly 45 unique games for 10 agents
- Each pair (i,j) where i < j plays exactly once
- Games must be executed in a consistent, deterministic order
- No agent can play against themselves

**Game Execution Order** [Source: architecture/backend-architecture.md#sequential-game-execution]
Games must be executed sequentially (not in parallel) to ensure:
- Deterministic power evolution
- Consistent game history for each subsequent decision
- Proper tracking of game numbers within round

### Component Specifications
**AsyncFlow Base Class** [Source: architecture/backend-architecture.md#node-base-classes]
```python
class AsyncFlow:
    """Base class for orchestrating multiple nodes"""
    def __init__(self):
        self.nodes = []

    async def run(self, context: dict) -> dict:
        for node in self.nodes:
            context = await node.execute(context)
        return context
```

**Sequential Execution Pattern** [Source: architecture/backend-architecture.md#sequential-game-execution]
```python
for i in range(len(agents)):
    for j in range(i + 1, len(agents)):
        game = await self.play_game(agents[i], agents[j])
        self.update_powers(agents[i], agents[j], game)
        games.append(game)
```

**Note:** The `update_powers` method call shown above is for illustration. Power updates are not implemented in this story but will be added in a future story

### File Locations
Based on the nested folder structure from architecture:
- `src/flows/game_execution.py` - Create new GameExecutionFlow class
- `src/flows/experiment.py` - Modify to integrate GameExecutionFlow
- `src/core/models.py` - Use existing Agent and GameResult dataclasses
- `src/utils/game_logic.py` - Contains payoff calculations (not power updates in this story)
- `test_game_execution.py` - New test file in project root

### Technical Constraints
- Games MUST be executed sequentially, not in parallel
- Each game needs unique game_id in format: "r{round}_g{game_num}"
- Game numbers run from 1 to 45 within each round
- Must maintain consistent ordering for reproducibility
- Power updates happen after each game (not implemented in this story)

### Project Structure Notes
The flows directory already exists with experiment.py. The GameExecutionFlow should follow the same pattern as other flows in the project. The sequential execution requirement is critical for maintaining deterministic results.

## Testing
- Test file location: `test_game_execution.py` in project root
- Test framework: pytest
- Test runner command: `pytest test_game_execution.py -v`
- Specific test cases required:
  1. test_generate_round_matchups_creates_45_pairs
  2. test_all_pairs_are_unique
  3. test_each_agent_plays_nine_games
  4. test_matchup_order_is_consistent
  5. test_game_id_format_is_correct
- Note: Follow existing test patterns from the project if any exist

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-30 | 1.0 | Initial story creation | Bob (SM) |
| 2025-01-30 | 1.1 | Fixed file paths and clarified integration points | Sarah (PO) |
| 2025-01-30 | 1.2 | Implemented round-robin tournament logic | James (Dev) |

## Dev Agent Record
### Agent Model Used
Claude 3 Opus (claude-opus-4-20250514)

### Debug Log References
- Created GameExecutionFlow class in src/flows/game_execution.py
- Integrated with existing RoundFlow in experiment.py
- Removed obsolete GameExecutionNode class
- All unit tests pass (10/10)

### Completion Notes List
- Successfully implemented round-robin tournament logic with exactly 45 games for 10 agents
- Ensured sequential execution of games as required by specifications
- Maintained consistent game ordering for reproducibility
- Game IDs follow the specified format: r{round}_g{game_num}
- Integration with existing flow architecture maintains backward compatibility
- Note: Actual game decisions (play_game method) returns placeholder values as per story scope

### File List
- src/flows/game_execution.py (new)
- src/flows/experiment.py (modified)
- test_game_execution.py (new)
- test_experiment.py (modified)

## QA Results

### Review Date: 2025-01-30

### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment

The implementation successfully achieves the core requirements of the round-robin tournament logic. The code is well-structured, follows the AsyncFlow pattern established in the project, and generates exactly 45 unique games for 10 agents as required. The sequential execution requirement is properly maintained, and the game ID format adheres to specifications.

Key strengths:
- Clean separation of concerns with GameExecutionFlow handling tournament logic
- Proper validation of matchup generation with clear error messages
- Comprehensive test coverage with 10 well-designed test cases
- Consistent with project architecture patterns

Areas for improvement identified and addressed:
1. The GameExecutionFlow inheritance and integration could be more consistent
2. Error handling could be enhanced for edge cases
3. Type hints could be more comprehensive

### Refactoring Performed

- **File**: src/flows/game_execution.py
  - **Change**: Added comprehensive docstrings to all methods
  - **Why**: The original implementation lacked detailed documentation
  - **How**: Added clear parameter descriptions, return types, and method purposes to improve code maintainability

- **File**: src/flows/game_execution.py
  - **Change**: Enhanced error handling in generate_round_matchups
  - **Why**: The validation only checked total count but not other edge cases
  - **How**: Added validation for empty agent list and minimum agent requirements

- **File**: src/flows/experiment.py
  - **Change**: Improved integration pattern consistency
  - **Why**: The GameExecutionFlow was being called differently than other nodes
  - **How**: Maintained the current working pattern but added clarifying comments about the design decision

### Compliance Check

- Coding Standards: ✓ Code follows Python conventions and project patterns
- Project Structure: ✓ Files are correctly placed according to architecture docs
- Testing Strategy: ✓ Comprehensive unit tests with good coverage
- All ACs Met: ✓ All acceptance criteria fully implemented

### Improvements Checklist

[x] Added comprehensive docstrings to improve code documentation
[x] Enhanced error handling for edge cases in matchup generation
[x] Clarified integration pattern with comments
[ ] Consider extracting matchup generation algorithm to a separate utility for reusability
[ ] Add integration tests to verify flow interaction with RoundFlow
[ ] Consider adding performance benchmarks for large agent counts

### Security Review

No security concerns identified. The implementation:
- Does not expose sensitive data
- Uses proper input validation
- Follows secure coding practices

### Performance Considerations

The implementation is efficient for the current requirements:
- O(n²) complexity for matchup generation is optimal for round-robin
- Sequential execution is correctly implemented as required
- Memory usage is minimal with no unnecessary data retention

The logging at every 10 games provides good progress visibility without excessive I/O.

### Final Status

✓ Approved - Ready for Done

The implementation successfully meets all requirements and follows project standards. The code is clean, well-tested, and properly integrated. Minor improvements suggested above are nice-to-haves for future iterations but do not block completion.
