# Story 2.1: Parallel Strategy Collection

## Status
Done

## Story
**As a** system,
**I need to** collect strategies from 10 agents in parallel for efficiency,
**so that** round execution completes in reasonable time

## Acceptance Criteria
1. All 10 agents queried simultaneously
2. Responses collected within timeout
3. Failed agent responses handled gracefully

## Tasks / Subtasks
- [x] Task 1: Update StrategyCollectionNode to implement AsyncParallelBatchNode pattern (AC: 1)
  - [x] Subtask 1.1: Inherit from AsyncParallelBatchNode base class
  - [x] Subtask 1.2: Implement process_item method for single agent strategy collection
  - [x] Subtask 1.3: Override execute method to use execute_batch for parallel processing
  - [x] Subtask 1.4: Ensure all 10 agents are processed simultaneously using asyncio.gather
- [x] Task 2: Implement timeout handling for strategy collection (AC: 2)
  - [x] Subtask 2.1: Add timeout parameter to API client (default 30 seconds per call)
  - [x] Subtask 2.2: Use asyncio.wait_for to enforce timeout on each API call
  - [x] Subtask 2.3: Return None or default strategy for timed-out responses
  - [x] Subtask 2.4: Log timeout occurrences with agent ID and round number
- [x] Task 3: Add graceful error handling for failed agents (AC: 3)
  - [x] Subtask 3.1: Wrap individual agent processing in try/except blocks
  - [x] Subtask 3.2: Create fallback strategy for failed agents (e.g., "Always Cooperate")
  - [x] Subtask 3.3: Track and log API failures with error details
  - [x] Subtask 3.4: Ensure experiment continues even if some agents fail
  - [x] Subtask 3.5: Include failure count in round summary statistics
- [x] Task 4: Implement rate limiting for parallel API calls (AC: 1, 2)
  - [x] Subtask 4.1: Integrate RateLimiter from Story 1.3 into StrategyCollectionNode
  - [x] Subtask 4.2: Acquire rate limit token before each API call
  - [x] Subtask 4.3: Test rate limiting works correctly with 10 parallel requests
  - [x] Subtask 4.4: Ensure total request rate stays under 60 req/min for OpenRouter
- [x] Task 5: Create unit tests for parallel strategy collection (AC: 1, 2, 3)
  - [x] Subtask 5.1: Test successful parallel collection of 10 strategies
  - [x] Subtask 5.2: Test timeout handling with mocked slow API responses
  - [x] Subtask 5.3: Test graceful degradation when some agents fail
  - [x] Subtask 5.4: Test rate limiting prevents exceeding API limits
  - [x] Subtask 5.5: Verify all agents are queried simultaneously (not sequentially)

## Dev Notes

### Previous Story Insights
From Story 1.3 implementation:
- RateLimiter class already implemented in run_experiment.py to handle 60 req/min limit
- AsyncNode, AsyncFlow, and AsyncParallelBatchNode base classes exist in src/nodes.py
- API client integration working with proper error handling and retries
- DataManager saves strategies to `results/exp_YYYYMMDD_HHMMSS/rounds/strategies_r{N}.json`

### Data Models
**StrategyRecord Model** [Source: architecture/data-models.md#strategyrecord]
```python
@dataclass
class StrategyRecord:
    strategy_id: str  # Unique identifier
    agent_id: int  # Agent who created strategy (0-9)
    round: int  # Round number (1-10)
    strategy_text: str  # Concise strategy extracted from response
    full_reasoning: str  # Complete LLM response with reasoning
    prompt_tokens: int  # Tokens used in prompt
    completion_tokens: int  # Tokens in response
    model: str  # Model used (google/gemini-2.5-flash)
    timestamp: str  # ISO timestamp
```

### API Specifications
**OpenRouter API Client** [Source: architecture/external-apis.md#openrouter-api]
- Base URL: https://openrouter.ai/api/v1
- Endpoint: POST /chat/completions
- Headers: Authorization: Bearer {api_key}, Content-Type: application/json
- Rate Limit: 60 requests/minute for free tier
- Timeout: Recommend 30 seconds per request

**AsyncParallelBatchNode Pattern** [Source: architecture/backend-architecture.md#node-base-classes]
```python
class AsyncParallelBatchNode(AsyncNode):
    """Execute multiple async operations in parallel"""
    async def execute_batch(self, items: list) -> list:
        tasks = [self.process_item(item) for item in items]
        return await asyncio.gather(*tasks, return_exceptions=False)

    async def process_item(self, item):
        """Override in subclass to process single item"""
        raise NotImplementedError
```

### Component Specifications
**StrategyCollectionNode Implementation Pattern** [Source: architecture/backend-architecture.md#concurrent-strategy-collection]
```python
class StrategyCollectionNode(AsyncParallelBatchNode):
    def __init__(self, api_client: OpenRouterClient, rate_limiter: RateLimiter):
        self.api_client = api_client
        self.rate_limiter = rate_limiter

    async def process_item(self, agent: Agent) -> StrategyRecord:
        """Process single agent - called in parallel"""
        try:
            await self.rate_limiter.acquire()  # Rate limiting
            prompt = self.build_prompt(agent)
            response = await asyncio.wait_for(
                self.api_client.complete(prompt),
                timeout=30.0  # 30 second timeout
            )
            return self.parse_strategy(agent, response)
        except asyncio.TimeoutError:
            logger.error(f"Strategy collection timeout for agent {agent.id}")
            return self.create_fallback_strategy(agent)
        except Exception as e:
            logger.error(f"Strategy collection failed for agent {agent.id}: {e}")
            return self.create_fallback_strategy(agent)

    async def execute(self, context: dict) -> dict:
        agents = context["agents"]
        strategies = await self.execute_batch(agents)
        context["strategies"] = strategies
        return context
```

### File Locations
Based on the project structure [Source: architecture/project-structure.md]:
- `src/nodes.py` - Already contains base node classes, update StrategyCollectionNode here
- `src/api_client.py` - OpenRouterClient already exists
- `src/core/models.py` - StrategyRecord model should be added/verified here
- `test_strategy_collection.py` - New test file in project root
- Rate limiter is in `run_experiment.py` but may need to be moved to a shared location

### Testing Requirements
**Testing Standards** [Source: architecture/simple-testing-approach.md]
- Use pytest framework with pytest-asyncio for async tests
- Mock the OpenRouterClient to avoid API costs during testing
- Test file location: `test_strategy_collection.py` in project root
- Testing scenarios:
  1. Successful parallel collection of 10 strategies
  2. Timeout handling (mock slow responses)
  3. Error handling (mock API failures)
  4. Rate limiting compliance
  5. Verify parallel execution (not sequential)

### Technical Constraints
- Python 3.11+ required for modern async features [Source: architecture/tech-stack.md]
- Must respect OpenRouter rate limit of 60 req/min
- Each strategy collection should complete within 30 seconds
- Failed agents should not block the experiment
- All errors must be logged to experiment_errors.log

### Project Structure Notes
The existing node architecture from Story 1.2 provides the foundation. The StrategyCollectionNode is already partially implemented but needs to be updated to properly inherit from AsyncParallelBatchNode and implement true parallel execution with proper error handling and rate limiting.

## Testing
- Test file location: `test_strategy_collection.py` in project root
- Test framework: pytest with pytest-asyncio
- Mock OpenRouterClient to simulate various scenarios
- Specific test cases required:
  1. test_parallel_strategy_collection_success
  2. test_strategy_collection_with_timeouts
  3. test_strategy_collection_with_failures
  4. test_rate_limiting_compliance
  5. test_parallel_execution_verification

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-01-30 | 1.0 | Initial story creation | Bob (SM) |
| 2025-07-30 | 1.1 | Implemented all tasks and tests | James (Dev) |

## Dev Agent Record
### Agent Model Used
Claude 3.5 Sonnet

### Debug Log References
- Strategy collection timeout and error handling logged to experiment_errors.log
- Parallel execution timing logged to console via logger

### Completion Notes List
- Successfully updated StrategyCollectionNode to properly inherit from AsyncParallelBatchNode
- Implemented true parallel execution using asyncio.gather through execute_batch method
- Added comprehensive timeout handling with asyncio.wait_for (30s default)
- Created fallback strategies for failed/timed-out agents to ensure experiment continuity
- Integrated RateLimiter from run_experiment.py into the node initialization
- Added timeout parameter to OpenRouterClient API methods
- Created comprehensive test suite covering all acceptance criteria
- Note: Fallback strategies are counted as "successful" since they return valid StrategyRecord objects

### File List
- src/nodes.py (modified)
- src/api_client.py (modified)
- src/experiment.py (modified)
- run_experiment.py (modified)
- test_strategy_collection.py (created)

## QA Results

### Review Date: 2025-07-30

### Reviewed By: Quinn (Senior Developer QA)

### Code Quality Assessment

The implementation successfully achieves all acceptance criteria with high code quality. The StrategyCollectionNode properly inherits from AsyncParallelBatchNode and implements true parallel execution using asyncio.gather. Timeout handling is correctly implemented with asyncio.wait_for (30s default), and graceful error handling with fallback strategies ensures experiment continuity. The rate limiting integration is properly implemented, preventing API rate limit violations.

### Refactoring Performed

- **File**: src/nodes.py:226
  - **Change**: Added runtime validation check for context attribute
  - **Why**: Prevents silent failures if process_item is called outside of execute()
  - **How**: Raises clear error message helping developers understand proper usage

- **File**: src/nodes.py:320-344
  - **Change**: Enhanced strategy parsing robustness
  - **Why**: Original parsing was too simplistic and could fail on edge cases
  - **How**: Added better text extraction, empty string handling, and debug logging

- **File**: src/nodes.py:408-410, 419-421
  - **Change**: Added detailed failure tracking with timeout/error breakdown
  - **Why**: Better observability for debugging production issues
  - **How**: Separates timeout failures from other errors in logs and stats

- **File**: src/nodes.py:434
  - **Change**: Added context cleanup after execution
  - **Why**: Prevents memory leaks from holding context references
  - **How**: Explicitly deletes context attribute after use

### Compliance Check

- Coding Standards: ✓ Code follows Python best practices and project conventions
- Project Structure: ✓ Files are correctly placed according to architecture docs
- Testing Strategy: ✓ Comprehensive test coverage with all scenarios tested
- All ACs Met: ✓ All three acceptance criteria fully implemented

### Improvements Checklist

[Check off items you handled yourself, leave unchecked for dev to address]

- [x] Enhanced error handling and validation in process_item method
- [x] Improved strategy parsing robustness with better edge case handling
- [x] Added detailed failure tracking to distinguish timeouts from errors
- [x] Added memory cleanup to prevent context reference leaks
- [ ] Consider adding token usage tracking when API returns this data
- [ ] Consider extracting strategy parsing logic to a separate utility function
- [ ] Add metrics/monitoring hooks for production observability

### Security Review

No security issues identified. API keys are properly managed through the OpenRouterClient, and no sensitive data is logged.

### Performance Considerations

The parallel implementation is efficient, processing all 10 agents simultaneously with proper rate limiting. The 30-second timeout per agent ensures the round completes within reasonable time. Fallback strategies prevent individual failures from blocking the experiment.

### Final Status

✓ Approved - Ready for Done

The implementation is solid and production-ready. All acceptance criteria are met, and the code quality is high. The minor improvements suggested above are nice-to-haves that can be addressed in future iterations.
